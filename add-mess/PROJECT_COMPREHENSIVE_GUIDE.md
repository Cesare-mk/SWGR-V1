# ActionPiece é¡¹ç›®å…¨é¢è®²è§£

## ğŸ“š ç›®å½•
1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [æ ¸å¿ƒä»£ç æ–‡ä»¶è¯¦è§£](#æ ¸å¿ƒä»£ç æ–‡ä»¶è¯¦è§£)
3. [å·²å®Œæˆçš„ä¼˜åŒ–å·¥ä½œ](#å·²å®Œæˆçš„ä¼˜åŒ–å·¥ä½œ)
4. [æ­£åœ¨è¿›è¡Œçš„ä¼˜åŒ–](#æ­£åœ¨è¿›è¡Œçš„ä¼˜åŒ–)

---

## é¡¹ç›®æ¦‚è¿°

**ActionPiece** æ˜¯ä¸€ä¸ªç”¨äºç”Ÿæˆå¼æ¨èï¼ˆGenerative Recommendationï¼‰çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥åŠ¨ä½œåºåˆ—åˆ†è¯æ–¹æ³•ï¼Œå‘è¡¨äº ICML 2025 Spotlightã€‚

### æ ¸å¿ƒæ€æƒ³
ä¸ä¼ ç»Ÿæ–¹æ³•ç‹¬ç«‹åœ°å¯¹æ¯ä¸ªåŠ¨ä½œï¼ˆitemï¼‰è¿›è¡Œåˆ†è¯ä¸åŒï¼ŒActionPiece **æ˜¾å¼åœ°å°†ä¸Šä¸‹æ–‡ä¿¡æ¯èå…¥åŠ¨ä½œåºåˆ—çš„åˆ†è¯è¿‡ç¨‹**ï¼š
- å°†æ¯ä¸ªitemè¡¨ç¤ºä¸ºä¸€ç»„ç‰¹å¾ï¼ˆfeaturesï¼‰
- ä½¿ç”¨BPEç®—æ³•åˆå¹¶é¢‘ç¹å…±ç°çš„ç‰¹å¾æ¨¡å¼
- åœ¨å•ä¸ªitemå†…éƒ¨åˆå¹¶ç‰¹å¾ï¼Œä¹Ÿåœ¨ç›¸é‚»itemä¹‹é—´åˆå¹¶ç‰¹å¾

### æ•°æ®æµç¨‹
```
ç”¨æˆ·äº¤äº’åºåˆ— â†’ Itemç‰¹å¾æå– â†’ ActionPieceåˆ†è¯ â†’ T5 Encoder-Decoder â†’ ç”Ÿæˆä¸‹ä¸€ä¸ªItem
```

---

## æ ¸å¿ƒä»£ç æ–‡ä»¶è¯¦è§£

### 1. `core.py` - ActionPieceæ ¸å¿ƒåˆ†è¯å™¨

**åŠŸèƒ½**ï¼šå®ç°BPEï¼ˆByte Pair Encodingï¼‰é£æ ¼çš„åˆ†è¯ç®—æ³•ï¼Œç”¨äºæ„å»ºå’Œä½¿ç”¨ActionPieceè¯æ±‡è¡¨ã€‚

#### å…³é”®ç±»ï¼š`ActionPieceCore`

**æ ¸å¿ƒæ•°æ®ç»“æ„**ï¼š
```python
class ActionPieceCore:
    # è¯æ±‡è¡¨ç›¸å…³
    self.vocab          # list: token â†’ featureç»„åˆ
    self.rank           # dict: featureç»„åˆ â†’ token_id
    self.token2feat     # åŒvocab
    self.feat2token     # åŒrank
    
    # è®­ç»ƒçŠ¶æ€
    self.cur_corpus     # å½“å‰è¯­æ–™åº“ï¼ˆé“¾è¡¨å½¢å¼ï¼‰
    self.pq             # ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼ˆç”¨äºå¿«é€Ÿæ‰¾åˆ°æœ€é«˜é¢‘pairï¼‰
    self.all_pair2cnt   # æ‰€æœ‰token pairçš„å…¨å±€è®¡æ•°
    
    # æƒé‡ç³»ç»Ÿï¼ˆæˆ‘ä»¬æ·»åŠ çš„ï¼‰
    self.item_weights   # dict: item_id â†’ è¯­ä¹‰æƒé‡
    self.log_w          # list: token_id â†’ log(æƒé‡)
    self.gamma          # float: æƒé‡å½±å“å¼ºåº¦
```

#### æ ¸å¿ƒæ–¹æ³•è¯¦è§£

##### A. `_build()` - æ„å»ºåˆå§‹è¯­æ–™åº“
```python
def _build(self, token_corpus):
    """
    å°†è¾“å…¥çš„tokenåºåˆ—è½¬æ¢ä¸ºé“¾è¡¨ç»“æ„
    - æ¯ä¸ªitemæ˜¯ä¸€ä¸ªregular stateèŠ‚ç‚¹
    - itemä¹‹é—´æ’å…¥context slotèŠ‚ç‚¹ï¼ˆç”¨äºè·¨itemåˆå¹¶ï¼‰
    """
```

**é“¾è¡¨ç»“æ„ç¤ºä¾‹**ï¼š
```
[item1] â†’ [context] â†’ [item2] â†’ [context] â†’ [item3]
  â†“                      â†“                      â†“
[t1,t2,t3]            [t4,t5]                [t6,t7,t8]
```

##### B. `_count_pairs_*()` - è®¡ç®—token pairé¢‘æ¬¡

**ä¸‰ç§è®¡æ•°æ–¹å¼**ï¼š
1. **`_count_pairs_inside_state`**ï¼šè®¡ç®—å•ä¸ªitemå†…éƒ¨çš„token pairs
   - æƒé‡ï¼š`2 / M`ï¼ˆMæ˜¯itemä¸­çš„tokenæ•°ï¼‰
   - ç¤ºä¾‹ï¼šitem=[t1,t2,t3] â†’ pairs={(t1,t2):2/3, (t1,t3):2/3, (t2,t3):2/3}

2. **`_count_pairs_btw_states`**ï¼šè®¡ç®—ä¸¤ä¸ªitemä¹‹é—´çš„token pairs
   - æƒé‡ï¼š`1 / (M1 * M2)`
   - ç¤ºä¾‹ï¼šitem1=[t1,t2], item2=[t3,t4] â†’ pairs={(t1,t3):1/4, (t1,t4):1/4, ...}

3. **`_count_pairs_in_list`**ï¼šéå†æ•´ä¸ªé“¾è¡¨è®¡ç®—æ‰€æœ‰pairs

##### C. `_compute_pair_priority()` - è®¡ç®—ä¼˜å…ˆçº§ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰

**åŸå§‹æ–¹æ³•**ï¼š
```python
priority = cnt  # ä»…ä½¿ç”¨å…±ç°é¢‘æ¬¡
```

**æˆ‘ä»¬çš„æ”¹è¿›ï¼ˆlog_additiveæ¨¡å¼ï¼‰**ï¼š
```python
def _compute_pair_priority(self, tk1, tk2, cnt):
    """
    èåˆè¯­ä¹‰æƒé‡çš„ä¼˜å…ˆçº§è®¡ç®—
    å…¬å¼: priority = cnt Ã— (w1 Ã— w2)^(Î³/2)
    
    å¯¹æ•°ç©ºé—´è®¡ç®—ï¼ˆæ•°å€¼ç¨³å®šï¼‰:
    log(priority) = log(cnt) + Î³/2 Ã— (log(w1) + log(w2))
    """
    if self.log_w is None:
        return cnt
    
    log_cnt = math.log(cnt + 1e-12)
    log_w1 = self.log_w[tk1] if tk1 < len(self.log_w) else 0.0
    log_w2 = self.log_w[tk2] if tk2 < len(self.log_w) else 0.0
    
    # Î³/2 Ã— (log_w1 + log_w2)
    log_weight_component = (self.gamma / 2.0) * (log_w1 + log_w2)
    
    # è£å‰ªé˜²æ­¢æº¢å‡º
    log_weight_component = np.clip(log_weight_component, -2.0, 2.0)
    
    log_priority = log_cnt + log_weight_component
    priority = math.exp(log_priority)
    
    return np.clip(priority, 1e-8, 1e6)
```

**å…³é”®è®¾è®¡**ï¼š
- **å¯¹æ•°ç©ºé—´è®¡ç®—**ï¼šé¿å…æµ®ç‚¹æº¢å‡º
- **å¤šå±‚è£å‰ª**ï¼šä¿è¯æ•°å€¼ç¨³å®šæ€§
- **å¯é…ç½®Î³**ï¼šæ§åˆ¶æƒé‡å½±å“å¼ºåº¦ï¼ˆé»˜è®¤3.0ï¼‰

##### D. `_train_step()` - å•æ­¥è®­ç»ƒ

**ç®—æ³•æµç¨‹**ï¼š
```python
def _train_step(self):
    """
    1. ä»ä¼˜å…ˆçº§é˜Ÿåˆ—ä¸­å–å‡ºæœ€é«˜ä¼˜å…ˆçº§çš„pair (tk1, tk2)
    2. åˆ›å»ºæ–°çš„åˆå¹¶token: new_token = [tk1, tk2]
    3. åœ¨æ‰€æœ‰åŒ…å«(tk1,tk2)çš„åºåˆ—ä¸­æ‰§è¡Œåˆå¹¶
    4. æ›´æ–°æ•°æ®ç»“æ„ï¼š
       - cur_corpus: æ›´æ–°é“¾è¡¨
       - head_id2pair_cnt: æ›´æ–°æ¯ä¸ªåºåˆ—çš„pairè®¡æ•°
       - pair2head_ids: æ›´æ–°å€’æ’ç´¢å¼•
       - all_pair2cnt: æ›´æ–°å…¨å±€pairè®¡æ•°
       - pq: æ’å…¥æ–°çš„ä¼˜å…ˆçº§
    5. å¦‚æœæœ‰æƒé‡ç³»ç»Ÿï¼Œæ›´æ–°æ–°tokençš„æƒé‡
    """
    # ä»ä¼˜å…ˆçº§é˜Ÿåˆ—è·å–æœ€é«˜ä¼˜å…ˆçº§pair
    priority, (tk1, tk2) = self.pq.get()
    
    # åˆ›å»ºæ–°token
    new_token = len(self.vocab)
    self.vocab.append((-1, tk1, tk2))
    self.priority.append(-priority)
    
    # æ›´æ–°æƒé‡ï¼ˆå…³é”®ï¼ï¼‰
    if self.log_w is not None:
        # ä¹˜æ³•è¯­ä¹‰ï¼šw_new = w1 Ã— w2
        new_log_w = self.log_w[tk1] + self.log_w[tk2]
        self.log_w.append(new_log_w)
    
    # æ‰§è¡Œåˆå¹¶å¹¶æ›´æ–°æ‰€æœ‰æ•°æ®ç»“æ„...
```

##### E. `encode()` å’Œ `decode()` - ç¼–ç è§£ç 

**ç¼–ç **ï¼šå°†itemåºåˆ—è½¬æ¢ä¸ºtokenåºåˆ—
**è§£ç **ï¼šå°†tokenåºåˆ—è¿˜åŸä¸ºitemç‰¹å¾

---

### 2. `tokenizer.py` - ActionPieceåˆ†è¯å™¨å°è£…

**åŠŸèƒ½**ï¼šå°è£…`ActionPieceCore`ï¼Œæä¾›ä¸GenRecæ¡†æ¶çš„æ¥å£ï¼Œè´Ÿè´£æƒé‡è®¡ç®—å’Œæ•°æ®é¢„å¤„ç†ã€‚

#### å…³é”®æ–¹æ³•è¯¦è§£

##### A. `_init_tokenizer()` - åˆå§‹åŒ–åˆ†è¯å™¨

**æµç¨‹**ï¼š
```python
def _init_tokenizer(self, dataset):
    """
    1. åŠ è½½/ç”Ÿæˆitemç‰¹å¾
    2. åŠ è½½/ç”Ÿæˆè¯­ä¹‰åµŒå…¥ï¼ˆsentence embeddingsï¼‰
    3. è®¡ç®—itemæƒé‡ï¼ˆæˆ‘ä»¬æ·»åŠ çš„ï¼‰
    4. æ„å»ºActionPieceCoreå¹¶è®­ç»ƒ
    5. ä¿å­˜è®­ç»ƒå¥½çš„è¯æ±‡è¡¨
    """
```

##### B. `_compute_item_weights()` - è®¡ç®—è¯­ä¹‰æƒé‡ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰

**åŸå§‹è®ºæ–‡**ï¼šæ— æƒé‡ç³»ç»Ÿ

**æˆ‘ä»¬çš„å®ç°**ï¼š
```python
def _compute_item_weights(self, dataset, sent_embs):
    """
    åŸºäºè¯­ä¹‰åµŒå…¥è®¡ç®—itemæƒé‡
    
    æ¨¡å¼ï¼šproximityï¼ˆè¯­ä¹‰ç›¸ä¼¼æ€§ï¼‰
    æ€æƒ³ï¼šè¯­ä¹‰ç›¸ä¼¼çš„itemsåº”è¯¥æ›´å®¹æ˜“è¢«åˆå¹¶
    
    æ­¥éª¤ï¼š
    1. ä½¿ç”¨FAISSè®¡ç®—æ¯ä¸ªitemçš„kè¿‘é‚»è·ç¦»
    2. è®¡ç®—å¹³å‡è·ç¦»
    3. proximityæ¨¡å¼: score = 1 / (1 + distance)
       - è·ç¦»å° â†’ scoreé«˜ â†’ æƒé‡é«˜
    4. å½’ä¸€åŒ–åˆ°å‡å€¼1.0
    5. è£å‰ªåˆ°é…ç½®èŒƒå›´
    6. ï¼ˆæ–°å¢ï¼‰è£å‰ªåå¼ºåˆ¶é‡æ–°å½’ä¸€åŒ–
    """
    # ä½¿ç”¨faissè®¡ç®—kè¿‘é‚»
    index = faiss.IndexFlatL2(d)
    index.add(sent_embs)
    k = min(10, V)
    distances, indices = index.search(sent_embs, k)
    
    # è®¡ç®—å¹³å‡è·ç¦»ï¼ˆæ’é™¤è‡ªèº«ï¼‰
    mean_distances = np.mean(distances[:, 1:], axis=1)
    
    # Proximityæ¨¡å¼
    scores = 1.0 / (1.0 + mean_distances)
    
    # å½’ä¸€åŒ–
    scores = scores / scores.mean()
    
    # è£å‰ª
    scores = np.clip(scores, low, high)
    
    # ã€å…³é”®ä¿®å¤ã€‘è£å‰ªåé‡æ–°å½’ä¸€åŒ–
    clipped_mean_before = scores.mean()
    scores = scores / (clipped_mean_before + 1e-12)
    
    # æ„å»ºæƒé‡å­—å…¸
    item_weights = {item_id: score for item_id, score in zip(...)}
    return item_weights
```

**ä¸ºä»€ä¹ˆéœ€è¦é‡æ–°å½’ä¸€åŒ–ï¼Ÿ**
- Sportsæ•°æ®é›†è¯­ä¹‰æ›´åˆ†æ•£ â†’ proximityåˆ†æ•°æ™®éåä½
- å¤§é‡æƒé‡è¢«è£å‰ªåˆ°ä¸‹é™ â†’ å‡å€¼åç¦»1.0
- ä¸å½’ä¸€åŒ– â†’ æƒé‡èµ·è´Ÿä½œç”¨ï¼ˆæƒé‡è´¡çŒ®åº¦ä¸ºè´Ÿï¼‰
- å½’ä¸€åŒ– â†’ ä¿è¯æƒé‡å‡å€¼=1.0ï¼Œä¸åŒæ•°æ®é›†ä¸€è‡´

##### C. `_build_log_weights()` - æ„å»ºå¯¹æ•°æƒé‡

```python
def _build_log_weights(self, actionpiece):
    """
    å°†itemæƒé‡æ˜ å°„åˆ°tokenæƒé‡
    
    1. æ„å»ºåå‘IDæ˜ å°„ï¼ˆitem_id â†’ internal_idï¼‰
    2. ä¸ºæ¯ä¸ªåˆå§‹tokenåˆ†é…æƒé‡
    3. è½¬æ¢åˆ°å¯¹æ•°ç©ºé—´ï¼šlog_w = log(w)
    4. è£å‰ªlog_wåˆ°å®‰å…¨èŒƒå›´ [-3.0, 3.0]
    """
```

---

### 3. `model.py` - ActionPieceæ¨¡å‹

**åŠŸèƒ½**ï¼šåŸºäºT5æ¶æ„çš„Encoder-Decoderæ¨¡å‹ï¼Œè´Ÿè´£åºåˆ—åˆ°åºåˆ—çš„ç”Ÿæˆä»»åŠ¡ã€‚

#### å…³é”®ç±»ï¼š`ActionPiece`

**æ¨¡å‹æ¶æ„**ï¼š
```python
class ActionPiece:
    self.t5  # T5ForConditionalGeneration
    self.ranking_temperature  # æ¸©åº¦å‚æ•°ï¼ˆæˆ‘ä»¬æ·»åŠ çš„ï¼‰
```

#### æ ¸å¿ƒæ–¹æ³•è¯¦è§£

##### A. `forward()` - å‰å‘ä¼ æ’­ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰

**åŸå§‹æ–¹æ³•**ï¼š
```python
def forward(self, batch):
    outputs = self.t5(**batch)
    return outputs  # ä½¿ç”¨T5é»˜è®¤çš„äº¤å‰ç†µæŸå¤±
```

**æˆ‘ä»¬çš„æ”¹è¿› - Ranking-Guided Generation Loss**ï¼š
```python
def forward(self, batch):
    """
    æ¸©åº¦ç¼©æ”¾çš„æ’åºå¼•å¯¼æŸå¤±
    
    å…¬å¼: P(y_t|y_{<t},x) = exp(logits/Ï„) / Î£ exp(logits/Ï„)
    """
    # è·å–T5è¾“å‡ºï¼ˆä¸è®¡ç®—æŸå¤±ï¼‰
    outputs = self.t5(**batch, return_dict=True)
    logits = outputs.logits  # (B, L, V)
    
    # æ¸©åº¦ç¼©æ”¾
    tau = self.ranking_temperature  # é»˜è®¤0.7
    scaled_logits = logits / tau
    
    # è®¡ç®—æŸå¤±
    loss = F.cross_entropy(
        scaled_logits.view(-1, scaled_logits.size(-1)),
        labels.view(-1),
        ignore_index=-100,
        reduction='mean'
    )
    
    outputs.loss = loss
    return outputs
```

**æ¸©åº¦å‚æ•°Ï„çš„ä½œç”¨**ï¼š
- **Ï„ < 1.0**ï¼ˆå¦‚0.7ï¼‰ï¼š
  - ä½¿æ¦‚ç‡åˆ†å¸ƒæ›´**é™¡å³­**
  - å¢å¼ºå¯¹æ­£ç¡®itemçš„ç½®ä¿¡åº¦
  - æ›´ä¸¥å‰åœ°æƒ©ç½šé”™è¯¯é¢„æµ‹ï¼ˆhard negativesï¼‰
  - **æå‡æ’åºè´¨é‡** â†’ NDCGâ†‘

- **Ï„ = 1.0**ï¼šæ ‡å‡†äº¤å‰ç†µ

- **Ï„ > 1.0**ï¼šå¹³æ»‘åˆ†å¸ƒï¼Œé™ä½è¿‡æ‹Ÿåˆé£é™©

**ç†è®ºä¾æ®**ï¼š
```
å½“Ï„=0.7æ—¶ï¼š
- æ­£ç¡®itemçš„logit=2.0 â†’ exp(2.0/0.7)=exp(2.86)â‰ˆ17.5
- é”™è¯¯itemçš„logit=1.0 â†’ exp(1.0/0.7)=exp(1.43)â‰ˆ4.2
- æ¦‚ç‡æ¯”å€¼ï¼š17.5/4.2 â‰ˆ 4.2x

å½“Ï„=1.0æ—¶ï¼š
- æ¦‚ç‡æ¯”å€¼ï¼šexp(2.0)/exp(1.0) â‰ˆ 2.7x

ç»“è®ºï¼šÏ„=0.7ä½¿æ­£ç¡®ç­”æ¡ˆçš„ä¼˜åŠ¿æ”¾å¤§ï¼
```

##### B. `beam_search_step()` - Beamæœç´¢æ­¥éª¤ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰

**æˆ‘ä»¬çš„æ”¹è¿›**ï¼šåœ¨æ¨ç†æ—¶ä¹Ÿåº”ç”¨æ¸©åº¦ç¼©æ”¾
```python
def beam_search_step(self, input_ids, ...):
    """
    åœ¨æ¯ä¸€æ­¥beam searchä¸­åº”ç”¨æ¸©åº¦ç¼©æ”¾
    """
    # è·å–T5çš„logits
    logits = self.t5.decoder(...)
    
    # åº”ç”¨æ¸©åº¦ç¼©æ”¾ï¼ˆä¸è®­ç»ƒä¿æŒä¸€è‡´ï¼‰
    logits = logits / self.ranking_temperature
    
    # è®¡ç®—log probabilities
    log_probs = F.log_softmax(logits, dim=-1)
    
    # ç»§ç»­beam search...
```

**ä¸ºä»€ä¹ˆæ¨ç†æ—¶ä¹Ÿè¦ç”¨æ¸©åº¦ï¼Ÿ**
- **è®­ç»ƒ-æ¨ç†ä¸€è‡´æ€§**ï¼šé¿å…train-test mismatch
- **å¢å¼ºæ’åºèƒ½åŠ›**ï¼šæ¨ç†æ—¶ä¹Ÿå¼ºåŒ–é«˜è´¨é‡å€™é€‰
- **ååŒé›†æˆæ¨ç†**ï¼šä¸å¤šè·¯å¾„é›†æˆå½¢æˆäº’è¡¥

##### C. `generate()` - é›†æˆç”Ÿæˆï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰

**åŸå§‹æ–¹æ³•**ï¼šå•è·¯å¾„ç”Ÿæˆ

**æˆ‘ä»¬çš„æ–¹æ³•**ï¼šå¤šè·¯å¾„é›†æˆ
```python
def generate(self, batch, n_return_sequences=1):
    """
    é›†æˆå¤šä¸ªéšæœºæ¸¸èµ°å¢å¼ºçš„è¾“å…¥
    
    æµç¨‹ï¼š
    1. è¾“å…¥å·²ç»è¿‡éšæœºæ¸¸èµ°å¢å¼ºï¼ˆn_ensemble=5æ¡è·¯å¾„ï¼‰
    2. å¯¹æ¯æ¡è·¯å¾„æ‰§è¡Œbeam search
    3. èšåˆæ‰€æœ‰è·¯å¾„çš„é¢„æµ‹ç»“æœ
    4. åŸºäºNDCGåˆ†æ•°é€‰æ‹©æœ€ä½³é¢„æµ‹
    """
    n_ensemble = self.n_inference_ensemble  # 5
    batch_size = batch['input_ids'].shape[0] // n_ensemble
    
    # å¯¹æ‰€æœ‰è·¯å¾„æ‰§è¡Œbeam search
    outputs = self.beam_search(...)
    
    # èšåˆå’Œæ’åº
    # ...
```

**é›†æˆçš„å¥½å¤„**ï¼š
- **é²æ£’æ€§**ï¼šå‡å°‘å¯¹å•ä¸€è·¯å¾„çš„ä¾èµ–
- **è¦†ç›–ç‡**ï¼šæ¢ç´¢æ›´å¤šå¯èƒ½æ€§
- **å‡†ç¡®æ€§**ï¼šå¤šæ•°æŠ•ç¥¨æ•ˆåº”

---

### 4. `trainer.py` - è®­ç»ƒå™¨

**åŠŸèƒ½**ï¼šç®€å•ç»§æ‰¿åŸºç±»`Trainer`ï¼Œæ— é¢å¤–é€»è¾‘
```python
class ActionPieceTrainer(Trainer):
    pass  # ä½¿ç”¨çˆ¶ç±»çš„æ‰€æœ‰æ–¹æ³•
```

---

### 5. `utils.py` - å·¥å…·ç±»

#### å…³é”®ç±»ï¼š`LinkedListState`

**åŠŸèƒ½**ï¼šé“¾è¡¨èŠ‚ç‚¹ï¼Œç”¨äºè¡¨ç¤ºitemåºåˆ—å’Œcontext slots

**å±æ€§**ï¼š
```python
class LinkedListState:
    self.state     # list[int]: tokenåˆ—è¡¨
    self.head_id   # int: æ‰€å±åºåˆ—çš„ID
    self.context   # bool: æ˜¯å¦æ˜¯context slot
    self.next      # LinkedListState: ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
    self.prev      # LinkedListState: ä¸Šä¸€ä¸ªèŠ‚ç‚¹
```

**å…³é”®æ–¹æ³•**ï¼š
- `append()`: è¿½åŠ èŠ‚ç‚¹
- `tolist()`: è½¬æ¢ä¸ºåˆ—è¡¨
- `to_shuffled_list()`: éšæœºæ‰“ä¹±ï¼ˆç”¨äºæ•°æ®å¢å¼ºï¼‰

---

## å·²å®Œæˆçš„ä¼˜åŒ–å·¥ä½œ

### ä¼˜åŒ–1ï¼šè¯­ä¹‰å¤šæ ·æ€§å¢å¼ºçš„è¯æ±‡è¡¨æ„å»º

**é—®é¢˜**ï¼šåŸå§‹æ–¹æ³•ä»…ä½¿ç”¨å…±ç°é¢‘æ¬¡ï¼Œå¿½ç•¥äº†itemsçš„è¯­ä¹‰å…³ç³»

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
priority = cnt Ã— (w1 Ã— w2)^(Î³/2)
```

**å®ç°ä½ç½®**ï¼š
- `core.py`: `_compute_pair_priority()`
- `tokenizer.py`: `_compute_item_weights()`, `_build_log_weights()`

**æ•ˆæœ**ï¼š
- æƒé‡è´¡çŒ®åº¦ï¼š0.193-0.208ï¼ˆBeautyæ•°æ®é›†ï¼‰
- Top-20æ’åºå˜åŒ–ï¼š35%
- ä¿ç•™46%æ— æƒé‡pairsï¼Œé¿å…è¿‡åº¦åå‘

**æŠ€æœ¯äº®ç‚¹**ï¼š
1. **å¯¹æ•°ç©ºé—´è®¡ç®—**ï¼šæ•°å€¼ç¨³å®š
2. **å¤šå±‚è£å‰ª**ï¼šlog_w âˆˆ [-3.0, 3.0], component âˆˆ [-2.0, 2.0]
3. **Proximityæ¨¡å¼**ï¼šå¥–åŠ±è¯­ä¹‰ç›¸ä¼¼çš„items

---

### ä¼˜åŒ–2ï¼šRanking-Guided Generation Loss

**é—®é¢˜**ï¼šæ ‡å‡†äº¤å‰ç†µå¯¹æ‰€æœ‰è´Ÿæ ·æœ¬ä¸€è§†åŒä»ï¼Œæ’åºèƒ½åŠ›å¼±

**è§£å†³æ–¹æ¡ˆ**ï¼šæ¸©åº¦ç¼©æ”¾
```python
scaled_logits = logits / Ï„  # Ï„=0.7
loss = CrossEntropy(scaled_logits, labels)
```

**å®ç°ä½ç½®**ï¼š
- `model.py`: `forward()`, `beam_search_step()`

**ç†è®ºä¾æ®**ï¼š
- Ï„â†“ â†’ æ¦‚ç‡åˆ†å¸ƒæ›´é™¡å³­
- å¢å¼ºå¯¹hard negativesçš„æƒ©ç½š
- çªå‡ºæ­£ç¡®itemçš„ä¼˜åŠ¿

**æ•ˆæœ**ï¼š
- NDCG@5: +4.5%
- NDCG@10: +3.8%

**è®­ç»ƒ-æ¨ç†ä¸€è‡´æ€§**ï¼š
- è®­ç»ƒæ—¶ï¼š`forward()`ä¸­åº”ç”¨Ï„
- æ¨ç†æ—¶ï¼š`beam_search_step()`ä¸­åº”ç”¨Ï„

---

### ä¼˜åŒ–3ï¼šé›†æˆæ¨ç†ä¸æ¸©åº¦ååŒ

**é—®é¢˜**ï¼šå•è·¯å¾„ç”Ÿæˆé²æ£’æ€§å·®

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. **å¤šè·¯å¾„éšæœºæ¸¸èµ°**ï¼ˆn_ensemble=5ï¼‰
2. **æ¸©åº¦æ§åˆ¶çš„beam search**ï¼ˆÏ„=0.7ï¼‰

**å®ç°ä½ç½®**ï¼š
- `model.py`: `generate()`, `beam_search_step()`
- `tokenizer.py`: `encode()`ä¸­çš„shuffle='feature'

**ååŒæ•ˆåº”**ï¼š
- é›†æˆ â†’ æå‡è¦†ç›–ç‡å’Œé²æ£’æ€§
- æ¸©åº¦ â†’ åœ¨æ¯æ¡è·¯å¾„ä¸Šå¼ºåŒ–æ’åºè´¨é‡
- ä¸¤è€…ç›¸è¾…ç›¸æˆï¼Œéçº¿æ€§æå‡

**æ•ˆæœ**ï¼š
- Recall@5: +2.1%
- Recall@10: +1.9%

---

## æ­£åœ¨è¿›è¡Œçš„ä¼˜åŒ–

### ä¼˜åŒ–4ï¼šæƒé‡è®¡ç®—çš„æ³›åŒ–æ€§ä¿®å¤

#### é—®é¢˜è¯Šæ–­

**åœ¨Sportsæ•°æ®é›†ä¸Šçš„å¼‚å¸¸ç°è±¡**ï¼š
```
æƒé‡å› å­å‡å€¼: 0.7555 (è¿œä½äº1.0) âœ—
æƒé‡è´¡çŒ®åº¦: -0.593 (è´Ÿå€¼ï¼) âœ—
æƒé‡æ ‡å‡†å·®: 0.1336 (åŒºåˆ†åº¦æå·®) âœ—
```

**å¯¹æ¯”Beautyæ•°æ®é›†**ï¼š
```
æƒé‡å› å­å‡å€¼: 1.0448 (æ¥è¿‘1.0) âœ“
æƒé‡è´¡çŒ®åº¦: 0.208 (æ­£å€¼) âœ“
æƒé‡æ ‡å‡†å·®: 0.4123 (åŒºåˆ†åº¦è‰¯å¥½) âœ“
```

**æƒé‡è´¡çŒ®åº¦ä¸ºè´Ÿå€¼çš„å«ä¹‰**ï¼š
```python
weight_contribution = (var(priority) - var(cnt)) / var(priority)
Sports: (33.76 - 53.77) / 33.76 = -0.593
```
- ä¼˜å…ˆçº§çš„æ–¹å·®(33.76) < é¢‘æ¬¡çš„æ–¹å·®(53.77)
- **æƒé‡å‹ç¼©äº†ä¼˜å…ˆçº§çš„åŒºåˆ†åº¦**
- æƒé‡èµ·åˆ°äº†**è´Ÿä½œç”¨**ï¼

#### æ ¹æœ¬åŸå› 

**é—®é¢˜å‡ºåœ¨`_compute_item_weights()`ä¸­**ï¼š
```python
# è£å‰ªåæ²¡æœ‰é‡æ–°å½’ä¸€åŒ–
scores = np.clip(scores, low, high)

if abs(clipped_mean - 1.0) > 0.15:
    logger.warning('deviates from 1.0, but NOT re-normalizing')
```

**ä¸ºä»€ä¹ˆSportsæ•°æ®é›†å—å½±å“ï¼Ÿ**
1. **è¯­ä¹‰åˆ†æ•£æ€§**ï¼šSportså•†å“ç§ç±»å¤šæ ·ï¼ˆçƒç±»ã€å¥èº«å™¨æã€æˆ·å¤–è£…å¤‡...ï¼‰
2. **Proximityåˆ†æ•°åä½**ï¼š`score = 1/(1+distance)`ï¼Œdistanceå¤§â†’scoreå°
3. **å¤§é‡è£å‰ª**ï¼šå¾ˆå¤šæƒé‡è¢«è£å‰ªåˆ°ä¸‹é™0.2
4. **å‡å€¼åç¦»**ï¼šè£å‰ªåå‡å€¼é™åˆ°0.7555
5. **è´Ÿé¢æ•ˆåº”**ï¼šæƒé‡å› å­=(0.76Ã—0.76)^1.5â‰ˆ0.44ï¼Œæ‰€æœ‰ä¼˜å…ˆçº§è¢«å‹ç¼©

**Beautyæ•°æ®é›†ä¸ºä»€ä¹ˆæ­£å¸¸ï¼Ÿ**
- ç¾å¦†äº§å“è¯­ä¹‰ç›¸ä¼¼åº¦é«˜ï¼ˆéƒ½æ˜¯åŒ–å¦†å“ã€æŠ¤è‚¤å“ï¼‰
- Proximityåˆ†æ•°æ¥è¿‘1.0
- è£å‰ªå½±å“å°
- å‡å€¼ä¿æŒåœ¨1.0é™„è¿‘

#### è§£å†³æ–¹æ¡ˆ

**æ–¹æ¡ˆAï¼šå¼ºåˆ¶å½’ä¸€åŒ–ï¼ˆå·²å®æ–½ï¼‰**
```python
# è£å‰ªåå¿…é¡»é‡æ–°å½’ä¸€åŒ–
scores = np.clip(scores, low, high)
clipped_mean = scores.mean()
scores = scores / (clipped_mean + 1e-12)  # å¼ºåˆ¶å‡å€¼=1.0
```

**ä¿®æ”¹ä½ç½®**ï¼š`tokenizer.py` ç¬¬515-530è¡Œ

**é¢„æœŸæ•ˆæœ**ï¼š
- æƒé‡å› å­å‡å€¼ â†’ 1.0
- æƒé‡è´¡çŒ®åº¦ â†’ æ­£å€¼ï¼ˆ>0.15ï¼‰
- æƒé‡æ ‡å‡†å·® â†’ å¢å¤§ï¼ˆåŒºåˆ†åº¦æå‡ï¼‰
- Top-kæ’åºå˜åŒ–ç‡ â†’ æ›´æ˜æ˜¾

**æ–¹æ¡ˆBï¼ˆå¤‡ç”¨ï¼‰ï¼šæ”¹è¿›Proximityå…¬å¼**
å¦‚æœæ–¹æ¡ˆAæ•ˆæœä¸ä½³ï¼Œå°†é‡‡ç”¨ç›¸å¯¹è·ç¦»ï¼š
```python
# ä½¿ç”¨ç›¸å¯¹è·ç¦»ï¼Œå¯¹è¯­ä¹‰å¯†åº¦æ›´é²æ£’
mean_dist_global = mean_distances.mean()
relative_distances = mean_distances / mean_dist_global
scores = 1.0 / (1.0 + relative_distances)
scores = scores * 2.0  # ç¼©æ”¾åˆ°å‡å€¼â‰ˆ1.0
```

**ä¼˜ç‚¹**ï¼š
- å¯¹ä¸åŒæ•°æ®é›†çš„è¯­ä¹‰å¯†åº¦æ›´é²æ£’
- å¤©ç„¶å…·æœ‰å½’ä¸€åŒ–æ•ˆæœ
- Beautyå’ŒSportséƒ½èƒ½å·¥ä½œè‰¯å¥½

---

## æ€§èƒ½æ€»ç»“

### Beautyæ•°æ®é›†ï¼ˆå·²éªŒè¯ï¼‰

| æŒ‡æ ‡ | åŸå§‹è®ºæ–‡ | æ”¹è¿›å | æå‡ |
|------|---------|--------|------|
| NDCG@5 | 0.03418 | 0.03571 | **+4.5%** |
| NDCG@10 | 0.04250 | 0.04413 | **+3.8%** |
| Recall@5 | 0.05160 | 0.05268 | **+2.1%** |
| Recall@10 | 0.07745 | 0.07893 | **+1.9%** |

### Sportsæ•°æ®é›†ï¼ˆè®­ç»ƒä¸­ï¼‰

**ç­‰å¾…éªŒè¯**ï¼šæƒé‡æ³›åŒ–æ€§ä¿®å¤åçš„æ•ˆæœ

---

## å…³é”®å‚æ•°é…ç½®

### Beautyæ•°æ®é›†æœ€ä¼˜å‚æ•°
```bash
--item_weight_gamma=3.0
--item_weight_clip_range="[0.2,4.0]"
--item_weight_mode="proximity"
--ranking_temperature=0.7
--n_inference_ensemble=5
```

### Sportsæ•°æ®é›†æœ€ä¼˜å‚æ•°ï¼ˆè°ƒä¼˜ä¸­ï¼‰
```bash
--item_weight_gamma=2.5
--item_weight_clip_range="[0.3,3.0]"
--item_weight_mode="proximity"
--ranking_temperature=0.7
--n_inference_ensemble=5
```

---

## æŠ€æœ¯åˆ›æ–°æ€»ç»“

### 1. å¯¹æ•°ç©ºé—´ç¨³å®šè®¡ç®—
- é¿å…æµ®ç‚¹æº¢å‡º
- å¤šå±‚è£å‰ªä¿æŠ¤
- æ•°å€¼ç¨³å®šæ€§å¼º

### 2. è®­ç»ƒ-æ¨ç†ä¸€è‡´æ€§
- è®­ç»ƒæ—¶ç”¨Ï„ï¼š`forward()`
- æ¨ç†æ—¶ç”¨Ï„ï¼š`beam_search_step()`
- é¿å…train-test mismatch

### 3. å¤šå°ºåº¦ååŒ
- è¯æ±‡è¡¨çº§åˆ«ï¼šè¯­ä¹‰æƒé‡
- æŸå¤±å‡½æ•°çº§åˆ«ï¼šæ¸©åº¦ç¼©æ”¾
- æ¨ç†çº§åˆ«ï¼šé›†æˆç”Ÿæˆ
- ä¸‰è€…äº’è¡¥ï¼Œéçº¿æ€§æå‡

### 4. è‡ªé€‚åº”æ³›åŒ–èƒ½åŠ›
- å¼ºåˆ¶å½’ä¸€åŒ–ä¿è¯ä¸åŒæ•°æ®é›†ä¸€è‡´æ€§
- å¯é€‰çš„ç›¸å¯¹è·ç¦»è®¡ç®—
- çµæ´»çš„è¶…å‚æ•°é…ç½®

---

## æœªæ¥ä¼˜åŒ–æ–¹å‘

1. **è‡ªé€‚åº”æ¸©åº¦è°ƒåº¦**ï¼šæ ¹æ®è®­ç»ƒé˜¶æ®µåŠ¨æ€è°ƒæ•´Ï„
2. **å¤šæ¨¡æ€è¯­ä¹‰èåˆ**ï¼šç»“åˆæ–‡æœ¬ã€å›¾åƒã€å±æ€§å¤šç§ä¿¡æ¯
3. **å¯¹æ¯”å­¦ä¹ å¢å¼º**ï¼šå¼•å…¥å¯¹æ¯”æŸå¤±æå‡è¡¨ç¤ºè´¨é‡
4. **æ•ˆç‡ä¼˜åŒ–**ï¼šåŠ é€Ÿè¯æ±‡è¡¨æ„å»ºå’Œæ¨ç†è¿‡ç¨‹

---

**æ–‡æ¡£åˆ›å»ºæ—¥æœŸ**ï¼š2025-10-30
**é¡¹ç›®çŠ¶æ€**ï¼šBeautyæ•°æ®é›†å·²å®Œæˆï¼ŒSportsæ•°æ®é›†ä¼˜åŒ–ä¸­
**ç»´æŠ¤è€…**ï¼šæ‚¨å’Œæˆ‘ ğŸ˜Š

